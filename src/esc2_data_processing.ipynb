{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def create_window_seqs(window_size=20, input_csv_path=\"\", output_window_path=\"\"):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    windows =  set()\n",
    "    windows_list = []\n",
    "    no_of_segments = 0\n",
    "    for index, row in df.iterrows():\n",
    "        seq = row['seq']\n",
    "        base_index = 0\n",
    "        seq_len = len(seq)\n",
    "        while base_index <= seq_len:\n",
    "            seq_segment = seq[base_index: base_index+window_size]\n",
    "            base_index = base_index + window_size \n",
    "            if len(seq_segment) == window_size:\n",
    "                windows.add(seq_segment)\n",
    "                windows_list.append(seq_segment)\n",
    "                no_of_segments = no_of_segments + 1\n",
    "    print(f\"No_of_segments : {len(windows)}\")\n",
    "    print(f\"Lenght of sequences including duplicate: {len(windows_list)} \")\n",
    "    df1 = pd.DataFrame({'window': list(windows)})\n",
    "    df1.to_csv(output_window_path, index=False)\n",
    "    print(\"Windowed sequences sucessfully saved to path: \",output_window_path)\n",
    "    \n",
    "def create_featured_windows_without_zero_char(input_csv_path, output_csv_path):\n",
    "    ##Clean the windows segments having 000 such as CLDSFKEELDKY000000000AX\n",
    "    cleansed_seqs = []\n",
    "    df3 = pd.read_csv(input_csv_path)\n",
    "    for index, record in  df3.iterrows():\n",
    "        #Character to ignore: is 0\n",
    "        # print(f\"Index : {index} , record : {record['window_seqs']}\")\n",
    "        ignore_window_with_digit = \"0\"\n",
    "        if record['window_seqs'].__contains__(ignore_window_with_digit):\n",
    "            continue\n",
    "        cleansed_seqs.append(record['window_seqs'])\n",
    "    print(\"Total records in cleansed sequences: \", len(cleansed_seqs))\n",
    "    df4 = pd.DataFrame({'window_seqs' : list(cleansed_seqs)})    \n",
    "    df4.to_csv(output_csv_path, index=False)\n",
    "\n",
    "def construct_featured_window():\n",
    "    window_size = 20\n",
    "    input_csv_path = \"/home/perm/sars_escape_netv2/data/raw/cleansed_standard_len.csv\"\n",
    "    output_window_path = \"/home/perm/sars_escape_netv2/data/raw/feature_windows.csv\"\n",
    "    #create_window_seqs(input_csv_path, output_window_path)\n",
    "    create_featured_windows_without_zero_char(\"/home/perm/sars_escape_netv2/data/raw/feature_windows_v1.csv\",\n",
    "                                            \"/home/perm/sars_escape_netv2/data/raw/feature_windows_v2.csv\") \n",
    "# construct_featured_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_save_stanford_windows():\n",
    "    df  = pd.read_csv(db_path)\n",
    "    mutants = df['Mutation'].to_list()\n",
    "    # print(len(mutants))\n",
    "    # print(mutants[0:5])\n",
    "    wild_seq='''MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHV\n",
    "    SGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPF\n",
    "    LGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPI\n",
    "    NLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYN\n",
    "    ENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASV\n",
    "    YAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIAD\n",
    "    YNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYF\n",
    "    PLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFL\n",
    "    PFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLT\n",
    "    PTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLG\n",
    "    AENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGI\n",
    "    AVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDC\n",
    "    LGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIG\n",
    "    VTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDI\n",
    "    LSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLM\n",
    "    SFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNT\n",
    "    FVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVA\n",
    "    KNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDD\n",
    "    SEPVLKGVKLHYT'''\n",
    "    wild_seq = wild_seq.replace(\"\\n\", '')\n",
    "    wild_seq = wild_seq.replace(\" \", '')\n",
    "    print(len(wild_seq))\n",
    "    wild_seq_array = [amino_acid for amino_acid in wild_seq]\n",
    "    # print(len(wild_seq_array))\n",
    "    # wild_seq_array[0:5]\n",
    "    import copy\n",
    "    windows = []\n",
    "    window_size = 20\n",
    "    for mutant in mutants:\n",
    "        position = int(mutant[1:-1])  - 1 #For acutal zero based computation\n",
    "        # print(\"Actual Postion: \",position +1) #\n",
    "        mutated = mutant[-1]\n",
    "        original = mutant[0]\n",
    "        # print(f\" Original : {original} Mutated: \", mutated)\n",
    "        \n",
    "        assert original,  wild_seq_array[position]\n",
    "        # print(f' Oringal {original} and from wild_seq_array: {wild_seq_array[position]}')\n",
    "        \n",
    "        #Copy the wildarray with deep copy\n",
    "        mutated_seq = copy.deepcopy(wild_seq_array)\n",
    "        mutated_seq[position] = mutated\n",
    "        \n",
    "        # print(\"Mutated Seq: \", \"\".join(mutated_seq))\n",
    "        # print(\"New Seqence mutation residue: \", mutated_seq[position])\n",
    "        # print(\"wild sequence residue: \", wild_seq_array[position])\n",
    "        \n",
    "        #Exact 20 lenght window from position \n",
    "        start_pos = position - 10\n",
    "        end_pos = position + 10\n",
    "        if start_pos < 0:\n",
    "            start_pos = 0\n",
    "            end_pos = window_size\n",
    "        elif end_pos >1273:\n",
    "            end_pos = 1273\n",
    "            start_pos = 1273 - window_size\n",
    "        \n",
    "        window = \"\".join(mutated_seq[start_pos : end_pos]) #Extract sequenc array and convert to string\n",
    "        assert len(window), window_size \n",
    "        # print('Window Lenght : ', len(window))\n",
    "        windows.append(window)\n",
    "\n",
    "    print(f'Total windows:', len(windows))\n",
    "    df = pd.DataFrame(data={'window_seqs': windows, 'mutants' : mutants})\n",
    "\n",
    "    df.to_csv(csv_standford_mutant_file , index=False)\n",
    "    \n",
    "def evaluate_standford_escapeMutants(disc_model_path):\n",
    "    import EscapeNet2Executer as Esc \n",
    "    import tensorflow.keras.models as km\n",
    "    features  = Esc.get_single_window_feature(csv_standford_mutant_file)\n",
    "    model = km.load_model(disc_model_path) \n",
    "    model.summary()\n",
    "    evaluation_metrics = model.evaluate(features, np.ones( (features.shape[0], 1)))\n",
    "    # print(evaluation_metrics)\n",
    "    accuracy = evaluation_metrics[1] #0: loss 1 : Accuray | 2: Auc \n",
    "    return accuracy \n",
    "\n",
    "    # result = model.predict(features)\n",
    "    # print(\"Result shape: \", result.shape)\n",
    "    # boolean_result = result > 0.5\n",
    "    # #Accuracy \n",
    "    # correct_classification = np.sum(boolean_result)\n",
    "    # total_classification = len(boolean_result)\n",
    "    # print(f'Correct classfication: {correct_classification} Total Instance: {total_classification}')\n",
    "    # accuracy = correct_classification/total_classification\n",
    "    # print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 13:41:59.401087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-04-17 13:42:02.992644: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-04-17 13:42:02.992735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-04-17 13:42:03.094653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2024-04-17 13:42:03.094683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-04-17 13:42:03.094726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-04-17 13:42:03.094750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-04-17 13:42:03.095922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-04-17 13:42:03.096150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-04-17 13:42:03.098995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-04-17 13:42:03.099600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-04-17 13:42:03.099637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-04-17 13:42:03.105677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-04-17 13:42:03.106269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 13:42:03.109786: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-04-17 13:42:03.114695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2024-04-17 13:42:03.114749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-04-17 13:42:03.114789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-04-17 13:42:03.114822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-04-17 13:42:03.114868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-04-17 13:42:03.114910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-04-17 13:42:03.114952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-04-17 13:42:03.114993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-04-17 13:42:03.115027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-04-17 13:42:03.123233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-04-17 13:42:03.123271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-04-17 13:42:03.767466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-04-17 13:42:03.767507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-04-17 13:42:03.767515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-04-17 13:42:03.775809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11218 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 22, 20)       560         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 22, 256)      283648      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          525312      lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embed_layer (Concatenate)       (None, 512)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 28)           14364       embed_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 823,884\n",
      "Trainable params: 823,884\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Len of file 164\n",
      "2024-04-17 13:42:04.878735 | Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 13:42:04.887437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 3s 12ms/step\n",
      "2024-04-17 13:42:07.947216 | Done embedding.\n",
      "Shape of output previously:  (164, 22, 512)\n",
      "Reduced feature Shape after average:  (164, 512)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 2,561\n",
      "Trainable params: 1,537\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 13:42:08.188549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-04-17 13:42:08.208578: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400050000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8293 - auc: 0.0000e+00\n",
      "0.8292682766914368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 13:42:08.435814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-04-17 13:42:08.436717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# construct_save_stanford_windows()\n",
    "# model_1_path = \"/home/perm/sars_escape_netv2/data/model_results_archive/m3/results/epoch_25/disc_learning\"\n",
    "print(evaluate_standford_escapeMutants(\"/home/perm/cov/model/pretrain_models/discriminator-model/integrated_model\"))\n",
    "# accuracy_m20  = evaluate_standford_escapeMutants(\"/home/perm/sars_escape_netv2/data/model_results_archive/m20/sarsx_disc\")\n",
    "# accuracy_m19  = evaluate_standford_escapeMutants(\"/home/perm/sars_escape_netv2/data/model_results_archive/m19/sarsx_disc\")\n",
    "# accuracy_m15  = evaluate_standford_escapeMutants(\"/home/perm/sars_escape_netv2/data/model_results_archive/m15/sarsx_disc\")\n",
    "# accuracy_m16  = evaluate_standford_escapeMutants(\"/home/perm/sars_escape_netv2/data/model_results_archive/m16/sarsx_disc\")\n",
    "# accuracy_m17  = evaluate_standford_escapeMutants(\"/home/perm/sars_escape_netv2/data/model_results_archive/m17/sarsx_disc\")\n",
    "# accuracy_m18  = evaluate_standford_escapeMutants(\"/home/perm/sars_escape_netv2/data/model_results_archive/m18/sarsx_disc\")\n",
    "\n",
    "# accuracies  = {\n",
    "#                 'accuracy_m20': accuracy_m20,\n",
    "#                 'accuracy_m19': accuracy_m19,\n",
    "#                 'accuracy_m15': accuracy_m15,\n",
    "#                 'accuracy_m16': accuracy_m16,\n",
    "#                 'accuracy_m17' : accuracy_m17,\n",
    "#                 'accuracy_m18': accuracy_m18\n",
    "            #    }\n",
    "# print(f'Accuracies: ', accuracy_m20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SignficantEscapeGenerator as SEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_window_sequence_sarsx(file_path, window_size=20):\n",
    "    untranslated_residue = 'X'\n",
    "    seqs = SEG.read_sequences(file_path) #SeqList \n",
    "    # seqs = ['abcdefghijklmnopqrst', 'abcdefghijklmnopqrstuv']\n",
    "    segments = set() #duplication reducte \n",
    "    segments_including_duplicates = 0\n",
    "    untranslated_residue_counter = 0\n",
    "    for seq in seqs:\n",
    "        # print('Seq Len: ', len(seq))\n",
    "        base = 0 \n",
    "        offset = window_size\n",
    "        while offset <= len(seq):\n",
    "            # print(f'Base index {base} Offset Index :  {offset}')\n",
    "            segment = seq[base: offset]\n",
    "            # print(\"Segment Length:\", len(segment))\n",
    "            base = base + window_size\n",
    "            offset = offset + window_size\n",
    "            segments_including_duplicates += 1\n",
    "            if len(segment) != window_size:\n",
    "                # print('segment size not equal to 5', len(segment))\n",
    "                continue\n",
    "            if segment.__contains__(untranslated_residue):\n",
    "                untranslated_residue_counter +=1\n",
    "                continue\n",
    "            \n",
    "\n",
    "            \n",
    "            segments.add(segment)\n",
    "            \n",
    "    segments = list(segments)\n",
    "    print(f\"Total Uniques segments: {len(segments)} Total Segments including duplicates: {segments_including_duplicates} \" )\n",
    "    return segments\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Uniques segments: 27104 Total Segments including duplicates: 888530 \n",
      "Non significant sequences saves successfully to path: /home/perm/sars_escape_netv2/data/gen/non-significantx.csv\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/perm/sars_escape_netv2/data/gen/GISAIDX_NON_SIG.fa'\n",
    "non_sig_file_save_path = \"/home/perm/sars_escape_netv2/data/gen/non-significantx.csv\"\n",
    "segments_list  = construct_window_sequence_sarsx(file_path)\n",
    "df = pd.DataFrame({'window_seqs' : segments_list})\n",
    "df.to_csv(non_sig_file_save_path, index=False)\n",
    "print(f'Non significant sequences saves successfully to path: {non_sig_file_save_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "escapenet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
