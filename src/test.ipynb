{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sig seq len: 230997 , Non sig: 4381 type: <class 'list'> \n",
      "Sig sample record:  ['GVEGFNCYFPLQSYGFQPTN', 'KVGGNYNYRYRLFRKSNLKP']\n",
      "Non Sig sample record:  ['PIKDFGGFNFSQILPDPSKP', 'LFQCYLVPCYSLGPMVLRGL']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "BASE_DISC_TRAIN_PATH = \"/home/perm/sars_escape_netv2/data/disc/train/sarx\"\n",
    "DISCRIMINATOR_LEARNING_MODEL_PATH = \"/home/perm/sars_escape_netv2/model/sarsx_disc\"\n",
    "non_sig_path = BASE_DISC_TRAIN_PATH+\"/non-significantx.csv\"\n",
    "sig_path= BASE_DISC_TRAIN_PATH+\"/significantx.csv\"\n",
    "df1 = pd.read_csv(sig_path)\n",
    "sig_seqs = list(df1['window_seqs'])\n",
    "\n",
    "df2 = pd.read_csv(non_sig_path)\n",
    "non_sig_seqs = list(df2['window_seqs'])\n",
    "print(f'Sig seq len: {len(sig_seqs)} , Non sig: {len(non_sig_seqs)} type: {type(non_sig_seqs)} ')\n",
    "# print(\"Sig sample record: \",sig_seqs[0:2] )\n",
    "# print(\"Non Sig sample record: \",non_sig_seqs[0:2] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rand_array : 4381 , first 5 samples: [ 17196 110865 130776 215308 213855]\n",
      "Length of sig samples: 4381 , samples : ['YSFRPTYGVGHQPYRVVVLS' 'EIYQAGSTPCNGVGGFNCYF']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "rand_sig_indexes  = np.random.randint(0, len(sig_seqs), size=len(non_sig_seqs))\n",
    "print(f'len of rand_array : {len(rand_sig_indexes)} , first 5 samples: {rand_sig_indexes[0:5]}')\n",
    "# sig_seqs[rand_sig_indexes]\n",
    "sig_samples  = np.take(sig_seqs, rand_sig_indexes)\n",
    "print(f'Length of sig samples: {len(sig_samples)} , samples : {sig_samples[0:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EscapeNet2Executer as ESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_sarx(sequences):\n",
    "    fz_model  = ESC.load_fz_model()\n",
    "    X_cat, lengths  = ESC.featurize_seqs(sequences)\n",
    "    y_embed_output = fz_model.transform(X_cat, lengths)\n",
    "    print(\"Shape of output previously: \", y_embed_output.shape) \n",
    "    #Reducing the feature taking the avarage from middle axis\n",
    "    y_embed_output = np.average(y_embed_output, axis=1)\n",
    "    return y_embed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_features  = featurize_sarx(sig_samples)\n",
    "non_sig_features = featurize_sarx(non_sig_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sig_train  = get_features()\n",
    "non_sig_test  = get_features(BASE_DISC_TRAIN_PATH+\"/non_sig_combined_windows_test.csv\")\n",
    "sig_train_orig  = get_features(BASE_DISC_TRAIN_PATH+\"/significantx.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# sig_train_escape_aug = get_features_gan(GAN_AUG_SEQS)\n",
    "\n",
    "#Combine features from augmentation with sig_train_orig\n",
    "# sig_train_orig = np.concatenate( (sig_train_orig, sig_train_escape_aug), axis=0 )\n",
    "#Shuffle happens in place : ie orginal array directly modified\n",
    "np.random.shuffle(sig_train_orig)\n",
    "\n",
    "sig_test =  get_features(BASE_DISC_TRAIN_PATH+\"/sig_combined_windows_test.csv\")\n",
    "\n",
    "train_ds, val_ds = get_balanced_datasets_over_sampling(non_sig_train, non_sig_test, sig_train_orig, sig_test)\n",
    "\n",
    "model  = get_dense_model()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5) #  \n",
    "model.fit(train_ds,  epochs=NO_OF_EPOCHS_TO_TRAIN_DISC_NET, validation_data=val_ds,  callbacks= [callback], verbose=1) #verbose 1 = Progress bar\n",
    "\n",
    "model.save(DISCRIMINATOR_LEARNING_MODEL_PATH)\n",
    "print(\"**-------Discriminator Network sucessfully trained and saved to path-----***\",DISCRIMINATOR_LEARNING_MODEL_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "escapenet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
